===========================
THE PLACEMENT DOCUMENTATION
===========================
NOTE - You may read from the section N with placement --documentation N

INDEX
=====

1. WHAT IS PLACEMENT ?
2. CONFIGURING THE HARDWARE
3. USING placement WITH srun, cpu_bind or WITH numactl
4. HOW TO ADJUST YOUR placement COMMAND
5. WORKING IN DEPOPULATED MODE
6. USING MPIRUN INSTEAD OF SRUN
7. CHECKING YOUR RUNNING JOBS

1. WHAT IS PLACEMENT ?
======================

Thanks to placement you can:
		  1/ Easily control the placement of your processes of threads on multicores processors
		  2/ Control before the program execution that the wanted placement configuration is correct
		  3/ Check  running programs in order to detect bad placement issues

WARNING - placement has STRONG DEPENDENCIES with two tools: SLURM, and NUMACTL 
          So it may be difficult using placement with another shceduler than slurm

2. CONFIGURING THE HARDWARE
===========================

Before using placement, you should check, and probably edit, the configuration file (probably /usr/local/etc/placement/placement.conf)
It is a simple key-value file, structured in several sections. The purpose of this file is to help placement to guess,
using several environment variables, the hardware configuration of the underlying machine

This file is useful to let placement guess the architecture it runs on. The architecture is guessed using the hostname,
or special environment variables, useful namely for debugging, you could try for example:

# placement --hardware
Current architecture = Bullx_dlc (2 sockets/node, 10 cores/socket, 2 threads/core (hyperthreading on), 32768 Mb/socket, EXCLUSIVE)

You can check that the correct hardware is detected using the environment variables.
You can force an architecture with the environment variable:

export PLACEMENT_ARCHI=Bullx_dlc

This is useful mainly for debugging purpose


3. USING placement WITH srun, cpu_bind or WITH numactl
======================================================

It is very easy to configure cpu_bind arguments and thus place the processes and threads using srun.

For example, to call a job through srun and ensure the placement is correct, you could just
replace the standard srun call by the following:

srun $(placement) ./my_application

placement will then:
		  - guess the hardware configuration
		  - compute the srun-specific cpu_bind switch to distribute the processes and the threads among the available cores,
		  using a scatter algorithm. It is not necessary to specify the number of processes or the number of threads, 
		  because the environment variables SLURM_TASKS_PER_NODE and SLURM_CPUS_PER_TASK are used.

You may also use placement with the numactl command; for a 4 tasks, 4 threads/tasks job:
numactl $(placement 4 4 --numactl)

Or course, you have a lot of other options to control the placement as you need. See placement --help for more details.

4. HOW TO ADJUST YOUR placement COMMAND
=======================================

The cpu_bind switch is somewhat difficult to understand, unless you speak really well hexadecimal. Luckily, placement provides you 
with some very intuitive representations (the letters A,B,C,D represent the processes, in this example each process has 4 threads,
we are running on a bi-socket machine, each socket has 10 physical cores):

# placement 4 4 --ascii-art
  S0-------- S1-------- 
P AAAABBBB.. CCCCDDDD.. 

If you are used to cores numerotation, the following may be useful too:

# placement 4 4 --human
[ 0 1 2 3 ]
[ 4 5 6 7 ]
[ 10 11 12 13 ]
[ 14 15 16 17 ]

If you want to use hyperthreading, the following is for you:

# placement 4 4 --ascii-art --hyper
  S0-------- S1-------- 
P AABB...... CCDD...... 
L AABB...... CCDD...... 

The threads can be distributed in another way:

# placement 4 4 --ascii --mode=scatter_block --hyper
  S0-------- S1-------- 
P AAAA...... BBBB...... 
L CCCC...... DDDD...... 

Or even like this:

# placement 4 4 --ascii --mode=compact --hyper
  S0-------- S1-------- 
P AABBCCDD.. .......... 
L AABBCCDD.. .......... 

or like that:

# placement 4 4 --ascii --mode=compact 
  S0-------- S1-------- 
P AAAABBBBCC CCDDDD.... 

Please have a look to the switches --mode, --hyper, --hyper_as_physical

To use a given configuration in your script, you just have to replace --ascii-art or --human with --srun 
and call srun with placement. Here, we chose the second configuration:

srun $(placement 4 4 --srun --hyper) my_executable

This will generate and execute the awful command:

srun --cpu_bind=mask_cpu:0x300003,0xc0000c,0xc0000c00,0x300003000 my_executable

Some trick:
===========
It is good practise to put placement --ascii in top of your sbatch script, so that you'll know how
the threads should be placed, and you get a clear message if something goes wrong.

You could try something like the following:

placement --ascii
if [[ $? != 0 ]]
then
 echo "ERREUR DANS LE NOMBRE DE PROCESSES OU DE TACHES" 2>&1
 exit $?
fi

The job will not start if anything goes wrong (ie asking more threads than available cores).

5. WORKING IN DEPOPULATED MODE FOR HYPBRID CODES
================================================

It is easy to depopulate cores when you use placement.
Suppose you want to execute an mpi code counting N mpi processes on N bisocket, 10 cores/socket nodes,
thus 1 process/node, but you want to use only 16 cores/process, 8 cores/socket:

If using intel compilers, you should set KMP_AFFINITY with:
eval $(placement 1 16 --intel_affinity --verbose)

If using GNU compilers, you should set GOMP_AFFINITY with:
eval $(placement 1 16 --gnu_affinity)

Then call srun with:
srun $(placement 1 16) my_executable

6. USING mpirun INSTEAD OF srun
===============================

Sometimes, you'll want to use mpirun instead of srun. You'll thus have to use numactl to control the placement, instead of --cpu_bind switches
Considering the previous example: N mpi processes on N bisocket, 10 cores/socket nodes,
thus 1 process/node, but you want to use only 16 cores/process, 8 cores/socket, the placement commands are now:

eval $(placement 1 16 --intel_affinity --verbose)

mpirun  -n 2 numactl $(~/bin/placement 1 16 --numactl) ./exec_50k.x

7. CHECKING YOUR RUNNING JOBS WITH PLACEMENT
============================================

placement can be used to check a running job. For example, to chek the last runnig job you just launched,
you could run from the frontal node:

~/bin/placement --checkme --ascii --mem --thre --sorted_th
eoscomp102
  S0-------- S1-------- 
P ....A.A... AAA....... 
L AAAAAAAAAA .........A 

                0000000000 0000000000
                0000000000 1111111111
                0123456789 0123456789
  SOCKET MEMORY AAAAAAAAA. ..........
     PID    TID                        %CPU %MEM
A  32529  32553 .......... ..........   0.0 44.6
A         32599 A......... ..........  76.5 44.6
A         32551 .......... ..........   0.0 44.6
A         32595 .......... ..........   0.0 44.6
A         32602 .A........ ..........  76.5 44.6
A         32610 ..A....... ..........  76.5 44.6
A         32606 ...A...... ..........  76.5 44.6
A         32607 ....A..... ..........  76.5 44.6
A         32608 ....A..... ..........  76.5 44.6
A         32601 .....A.... ..........  76.5 44.6
A         32605 ......A... ..........  76.5 44.6
A         32609 ......A... ..........  76.5 44.6
A         32603 .......A.. ..........  76.5 44.6
A         32600 ........A. ..........  76.5 44.6
A         32596 .........A ..........  76.5 44.6
A         32597 .......... A.........  76.5 44.6
A         32604 .......... .A........  76.5 44.6
A         32598 .......... ..A.......  76.5 44.6
A         32529 .......... .........A  89.0 44.6

eoscomp103
  S0-------- S1-------- 
P .......AAA .AA..A.... 
L AAAAAA.A.. A..A.....A 

                0000000000 0000000000
                0000000000 1111111111
                0123456789 0123456789
  SOCKET MEMORY AAAAAAAAA. ..........
     PID    TID                        %CPU %MEM
A  63062  63075 .......... ..........   0.0 44.6
A         63118 A......... ..........  99.0 44.6
A         63073 .......... ..........   0.0 44.6
A         63115 .A........ ..........  99.0 44.6
A         63114 .......... ..........   0.0 44.6
A         63119 ..A....... ..........  99.5 44.6
A         63127 ...A...... ..........  99.5 44.6
A         63128 ....A..... ..........  99.0 44.6
A         63129 .....A.... ..........  99.5 44.6
A         63123 .......A.. ..........  99.0 44.6
A         63124 .......A.. ..........  99.0 44.6
A         63116 ........A. ..........  99.0 44.6
A         63121 .........A ..........  99.0 44.6
A         63126 .......... A.........  99.5 44.6
A         63117 .......... .A........  99.0 44.6
A         63122 .......... ..A.......  99.5 44.6
A         63120 .......... ...A......  99.5 44.6
A         63125 .......... .....A....  99.0 44.6
A         63062 .......... .........A  97.3 44.6

This shows that placement is very poor in this running job, on both nodes
Using the commands explained in Section S5, the situation can be improved,
and you can check this:

 ~/bin/placement --checkme --ascii --mem --thre --sorted_th
eoscomp8
  S0-------- S1-------- 
P AAAAAAAA.. AAAAAAAA.. 
L .......... .......... 

                0000000000 0000000000
                0000000000 1111111111
                0123456789 0123456789
  SOCKET MEMORY AAAAAAAAA. ..........
     PID    TID                        %CPU %MEM
A  98539  98539 A......... ..........  91.7 44.6
A         98563 .......... ..........   0.0 44.6
A         98561 .......... ..........   0.0 44.6
A         98644 .A........ ..........  82.0 44.6
A         98645 ..A....... ..........  81.6 44.6
A         98646 ...A...... ..........  81.6 44.6
A         98647 ....A..... ..........  82.0 44.6
A         98648 .....A.... ..........  81.6 44.6
A         98649 ......A... ..........  82.0 44.6
A         98650 .......A.. ..........  82.0 44.6
A         98651 .......... A.........  81.6 44.6
A         98643 .......... ..........   0.0 44.6
A         98652 .......... .A........  81.6 44.6
A         98653 .......... ..A.......  82.0 44.6
A         98654 .......... ...A......  82.0 44.6
A         98655 .......... ....A.....  82.0 44.6
A         98656 .......... .....A....  82.0 44.6
A         98657 .......... ......A...  82.0 44.6
A         98658 .......... .......A..  82.0 44.6

eoscomp17
  S0-------- S1-------- 
P AAAAAAAA.. AAAAAAAA.. 
L .......... .......... 

                0000000000 0000000000
                0000000000 1111111111
                0123456789 0123456789
  SOCKET MEMORY AAAAAAAAA. ..........
     PID    TID                        %CPU %MEM
A 106955 106955 A......... ..........  93.9 44.6
A        106968 .......... ..........   0.0 44.6
A        106966 .......... ..........   0.0 44.6
A        107047 .A........ ..........  94.3 44.6
A        107048 ..A....... ..........  94.3 44.6
A        107049 ...A...... ..........  94.3 44.6
A        107050 ....A..... ..........  94.0 44.6
A        107051 .....A.... ..........  94.0 44.6
A        107052 ......A... ..........  94.3 44.6
A        107053 .......A.. ..........  94.3 44.6
A        107054 .......... A.........  94.3 44.6
A        107046 .......... ..........   0.0 44.6
A        107055 .......... .A........  94.3 44.6
A        107056 .......... ..A.......  94.3 44.6
A        107057 .......... ...A......  94.3 44.6
A        107058 .......... ....A.....  94.3 44.6
A        107059 .......... .....A....  94.3 44.6
A        107060 .......... ......A...  94.0 44.6
A        107061 .......... .......A..  94.0 44.6

However, the line "SOCKET MEMORY" shows that the memory used by your process is
 allocated on one socket only: you could improve the code to change this behaviour.


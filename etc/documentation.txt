===========================
THE PLACEMENT DOCUMENTATION
===========================
NOTE - You may read only from the section N with the command:
placement --documentation N

INDEX
=====

1. WHAT IS PLACEMENT ?
2. CONFIGURING THE HARDWARE
3. USING placement WITH srun, cpu_bind or WITH numactl
4. HOW TO ADJUST YOUR placement COMMAND
5. WORKING IN DEPOPULATED MODE
6. USING MPIRUN INSTEAD OF SRUN
7. CHECKING YOUR RUNNING JOBS
8. 

1. WHAT IS PLACEMENT ?
======================

placement is a wrapper making easier for you to control the placement of your processes or threads on multicore processors
With placement you can:
		  1/ Control before the program execution that the wanted placement configuration is correct
		  2/ Check  running programs in order to detect bad placement issues

WARNING - placement has STRONG DEPENDENCIES with two tools: SLURM, and NUMACTL 
          So it may be difficult using placement with another scheduler than slurm

2. CONFIGURING THE HARDWARE AND DEBUGGING THE CONFIGURATION
===========================================================

placement looks for the slurm.conf file (using the environment variable $SLURM_CONF if it exists) to know the configuration,
so that if you use slurm you should not have anything to configure !

BUT if you use some other scheduler, OR if you want to check the placement behaviour on some other machine than your supercomputer,
you may edit the placement configuration file (${PLACEMENT_ROOT}/etc/placement.conf). This file is read BEFORE slurm.conf.

It is a simple key-value file, structured in several sections. The purpose of this file is to help placement to guess,
using several environment variables, the hardware configuration of the underlying machine

This file is useful to let placement guess the architecture it should run on, using the hostname or
or special environment variables. You could try for example:

# placement --hardware
Current architecture = Bullx_dlc (2 sockets/node, 10 cores/socket, 2 threads/core (hyperthreading on), 32768 Mb/socket, EXCLUSIVE)

You can force an architecture with the environment variable:
export PLACEMENT_ARCHI=Bullx_dlc


3. USING placement WITH srun, cpu_bind or WITH numactl
======================================================

It is very easy to configure cpu_bind arguments and thus place the processes and threads using srun.

For example, to call a job through srun and ensure the placement is correct, you could just
replace the standard srun call by the following:

srun $(placement) ./my_application

placement will then:
		  - guess the hardware configuration
		  - compute the srun-specific cpu_bind switch to distribute the processes and the threads among the available cores,
		  using a scatter algorithm. It is not necessary to specify the number of processes or the number of threads, 
		  because the environment variables SLURM_TASKS_PER_NODE and SLURM_CPUS_PER_TASK are used.

You may also use placement with the numactl command; for a 4 tasks, 4 threads/tasks job:
numactl $(placement 4 4 --numactl)

Of course, you have a lot of other options to control the placement as you need. See placement --help for more details.

4. HOW TO ADJUST YOUR placement COMMAND
=======================================

The cpu_bind switch is somewhat difficult to understand, unless you speak really well hexadecimal. Luckily, placement provides you 
with some very intuitive representations (the letters A,B,C,D represent the processes, in this example each process has 4 threads,
we are running on a bi-socket machine, each socket has 10 physical cores):

# placement 4 4 --ascii-art
  S0-------- S1-------- 
P AAAABBBB.. CCCCDDDD.. 

If you are used to cores numerotation, the following may be useful too:

# placement 4 4 --human
[ 0 1 2 3 ]
[ 4 5 6 7 ]
[ 10 11 12 13 ]
[ 14 15 16 17 ]

If you want to use hyperthreading, the following is for you:

# placement 4 4 --ascii-art --hyper
  S0-------- S1-------- 
P AABB...... CCDD...... 
L AABB...... CCDD...... 

The threads can be distributed in another way:

# placement 4 4 --ascii --mode=scatter_block --hyper
  S0-------- S1-------- 
P AAAA...... BBBB...... 
L CCCC...... DDDD...... 

Or even like this:

# placement 4 4 --ascii --mode=compact --hyper
  S0-------- S1-------- 
P AABBCCDD.. .......... 
L AABBCCDD.. .......... 

or like that:

# placement 4 4 --ascii --mode=compact 
  S0-------- S1-------- 
P AAAABBBBCC CCDDDD.... 

Please have a look to the switches --mode, --hyper, --hyper_as_physical

To use a given configuration in your script, you just have to replace --ascii-art or --human with --srun 
and call srun with placement. Here, we chose the second configuration:

srun $(placement 4 4 --srun --hyper) my_executable

This will generate and execute the awful command:

srun --cpu_bind=mask_cpu:0x300003,0xc0000c,0xc0000c00,0x300003000 my_executable

Some trick:
===========
It is good practice to put placement --ascii in top of your sbatch script, so that you'll know how
the threads should be placed, and you get a clear message if something goes wrong.

You could try something like the following:

placement --ascii
if [[ $? != 0 ]]
then
 echo "ERREUR DANS LE NOMBRE DE PROCESSES OU DE TACHES" 2>&1
 exit $?
fi

The job will not start if anything goes wrong (ie asking more threads than available cores).

5. WORKING IN DEPOPULATED MODE FOR HYPBRID CODES
================================================

It is easy to depopulate cores when you use placement.
Suppose you want to execute an mpi code counting N mpi processes on N bisocket, 10 cores/socket nodes,
thus 1 process/node, but you want to use only 16 cores/process, 8 cores/socket:

If using intel compilers, you should set KMP_AFFINITY with:
eval $(placement 1 16 --intel_affinity --verbose)

If using GNU compilers, you should set GOMP_AFFINITY with:
eval $(placement 1 16 --gnu_affinity)

Then call srun with:
srun $(placement 1 16) my_executable

6. USING mpirun INSTEAD OF srun
===============================

Sometimes, you'll want to use mpirun instead of srun. You'll thus have to use numactl to control the placement, instead of --cpu_bind switches
Considering the previous example: N mpi processes on N bisocket, 10 cores/socket nodes,
thus 1 process/node, but you want to use only 16 cores/process, 8 cores/socket, the placement commands are now:

eval $(placement 1 16 --intel_affinity --verbose)

mpirun  -n 2 numactl $(placement 1 16 --numactl) ./exec_50k.x

7. CHECKING YOUR RUNNING JOBS WITH PLACEMENT
============================================

placement can be used to check a running job. For example, to check the last running job you just launched,
you could run from the frontal node:

placement --checkme --ascii --memory --threads --sorted_threads
eoscomp103
  S0-------- S1-------- 
P .......AAA .AA..A.... 
L AAAAAA.A.. A..A.....A 

                0000000000 0000000000
                0000000000 1111111111
                0123456789 0123456789
     PID    TID                        %CPU %MEM
A  63062  63075 .......... ..........   0.0 44.6
A         63118 A......... ..........  99.0 44.6
A         63073 .......... ..........   0.0 44.6
A         63115 .A........ ..........  99.0 44.6
A         63114 .......... ..........   0.0 44.6
A         63119 ..A....... ..........  99.5 44.6
A         63127 ...A...... ..........  99.5 44.6
A         63128 ....A..... ..........  99.0 44.6
A         63129 .....A.... ..........  99.5 44.6
A         63123 .......A.. ..........  99.0 44.6
A         63124 .......A.. ..........  99.0 44.6
A         63116 ........A. ..........  99.0 44.6
A         63121 .........A ..........  99.0 44.6
A         63126 .......... A.........  99.5 44.6
A         63117 .......... .A........  99.0 44.6
A         63122 .......... ..A.......  99.5 44.6
A         63120 .......... ...A......  99.5 44.6
A         63125 .......... .....A....  99.0 44.6
A         63062 .......... .........A  97.3 44.6

  SOCKET MEMORY relative to the socket memory
A               *********. ..........

This shows that the placement is very poor in this running job. The threads
are not equally distributed on both sockets (10+8), and only the memory of 
the first socket is used.

Using the commands explained in Section S5, the situation can be improved,
and you can check this improvement:

placement --checkme --ascii --memory --threads --sorted_threads
eoscomp8
  S0-------- S1-------- 
P AAAAAAAA.. AAAAAAAA.. 
L .......... .......... 

                0000000000 0000000000
                0000000000 1111111111
                0123456789 0123456789
  SOCKET MEMORY AAAAAAAAA. ..........
     PID    TID                        %CPU %MEM
A  98539  98539 A......... ..........  91.7 44.6
A         98563 .......... ..........   0.0 44.6
A         98561 .......... ..........   0.0 44.6
A         98644 .A........ ..........  82.0 44.6
A         98645 ..A....... ..........  81.6 44.6
A         98646 ...A...... ..........  81.6 44.6
A         98647 ....A..... ..........  82.0 44.6
A         98648 .....A.... ..........  81.6 44.6
A         98649 ......A... ..........  82.0 44.6
A         98650 .......A.. ..........  82.0 44.6
A         98651 .......... A.........  81.6 44.6
A         98643 .......... ..........   0.0 44.6
A         98652 .......... .A........  81.6 44.6
A         98653 .......... ..A.......  82.0 44.6
A         98654 .......... ...A......  82.0 44.6
A         98655 .......... ....A.....  82.0 44.6
A         98656 .......... .....A....  82.0 44.6
A         98657 .......... ......A...  82.0 44.6
A         98658 .......... .......A..  82.0 44.6

  SOCKET MEMORY relative to the socket memory
A               *********. ..........

The threads distribution is already better, but the line "SOCKET MEMORY" 
shows that the memory used by your process is still
allocated on one socket only: you could improve the code to change this behaviour, 
then check again with placement.

8. DEBUGGING placement
======================

The following is for developers who want to debug placement:

-----------------------------------------
The environment variable PLACEMENT_DEBUG
-----------------------------------------
You can have a look to the external commands used by placement with this variable:

1/ To have the command line printed use:
export PLACEMENT_DEBUG=1

2/ To have the command line printed AND the raw result, use:
export PLACEMENT_DEBUG=2

3/ In a production environment, you'll prefer not to have output spoiled with those messages:
export -n PLACEMENT_DEBUG

-------------------------------------------
The environment variable PLACEMENT_DEBUG_1
-------------------------------------------
On a non-exclusive node, you can further debug the configuration:
export PLACEMENT_DEBUG_1='0-1' means that only sockets 0,1 are reserved for your job

You can even specify the complete cpuset: 
export PLACEMENT_DEBUG_1='0-1:10-15,16-21' means that only 12 cores on 2 sockets are reserved for your job

Of course, PLACEMENT_DEBUG_1 SHOULD BE USED ONLY FOR DEBUGGING PURPOSE, AND SHOULD BE UNSET FOR PRODUCTION !

When PLACEMENT_DEBUG_1 is not set, placement calls numactl --show to know the current reserved cpuset

You can simulate how placement will behave on your supercomputer, using two different syntaxes for $PLACEMENT_DEBUG_1:

1/ First syntax: SOCKETS granularity
------------------------------------
You can tell placement that the system did give you the sockets 1, 2, and 4:

# ( export PLACEMENT_ARCHI=vendor2; export PLACEMENT_DEBUG_1=1-2,4; ~/bin/placement 3 6   --mode=scatter --ascii )
  S0-------------- S1-------------- S2-------------- S3-------------- S4-------------- S5-------------- S6-------------- S7-------------- 
P                  AAAAAA.......... BBBBBB..........                  CCCCCC..........                  

2/ Second syntax: CORES granularity
-----------------------------------
You can tell placement that the system did give you the cores 20 to 23, 40 to 45, and 64 to 71, which are in the sockets 1,2 and 4:.
As we do not specify whole sockets, we cannot use scatter mode. However, you can still use the compact mode:

( export PLACEMENT_ARCHI=vendor2; export PLACEMENT_DEBUG_1='1,2,4:20-23,40-45,64-71'; ~/bin/placement 3 6   --mode=compact --ascii ) 
  S0-------------- S1-------------- S2-------------- S3-------------- S4-------------- S5-------------- S6-------------- S7-------------- 
P                  ....AAAA........ ........AABBBB..                  BBCCCCCC........


That's all Folks !

Have fun using placement !
Emmanuel
emmanuel.courcelle@inp-toulouse.fr
https://www.calmip.univ-toulouse.fr

